---
title: Buy The Dip
author: Fennon W.
date: '2019-11-24'
slug: buy-the-dip
categories:
  - Finance
tags:
  - r
  - alpha vantage
disableComments: no
---


Warren Buffett once said that as an investor, it is wise to be “Fearful when others are greedy and greedy when others are fearful.”




In a up trend on any timescale, a smart trader would "buy the dip" -- buy any time there's a sizeable selloff. Let's define an "up trend" in the broadest sense: if price is making higher **all time highs**, it's in an uptrend. So any time a new all time high is achieved, and price starts to slide, does buying into the selloff and fear produce positive returns?


We'll test this using **SPY**, the SPDR S&P500 ETF designed to track the S&P 500 stock market index. This ETF is very liquid, covers a broad range of stocks (so no cherry picking), and can be traded commission free by most brokerages. **However, trade at your own risk.** Neither I, nor your parents, nor Jesus are responsible for your financial decisions. 

To obtain historical ETF data, I used the <a href="https://github.com/business-science/alphavantager">alphavantager</a> R package to access the <a href="https://www.alphavantage.co/documentation/">Alpha Vantage API</a>; the <a href="https://github.com/business-science/tidyquant">tidyquant</a> package to calculate simple moving averages; and tidyverse, ggplot2, etc to wrangle and visualize data.

Price data covers approximately 20 years, from 1999 to 2019.


# Setup

Load libraries.

```{r echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(tidyquant)
library(reshape2)
library(ggplot2)
library(gridExtra)
library(lubridate)
library(alphavantager)
library(scales)
library(emo)
```

```
library(tidyverse)
library(tidyquant)
library(reshape2)
library(ggplot2)
library(lubridate)
library(alphavantager)
library(scales)
```

Set Alphavantager key.
```{r eval = FALSE}
av_api_key("my_key_goes_here")
```

```{r echo = FALSE}
av_api_key("ZVWHBIOOHGCNKHD3")
```

# Get Historical ETF Data

Get all available price data.

```{r eval = FALSE, message = FALSE}
av_get(symbol = "SPY"
       , av_fun = "TIME_SERIES_DAILY_ADJUSTED"
       , outputsize = "full") %>%
  mutate(row_id = row_number()) %>%
  select(row_id, timestamp, open, close) -> all_dat
```

```{r echo = FALSE}
all_dat <- readRDS("/Users/Fennon/Desktop/My Blog/projects/buy_the_dip/all_dat_fat.rds")
```

Let's take a look at ATHs over time.
```{r, echo = FALSE}
## calc all time highs (ath) + difference between ath
all_dat %>% 
  mutate(row_id = row_number()
         , ath = cummax(high)) %>% 
  group_by() %>% 
  mutate(diff_ath = ath - lag(ath)) %>% 
  ungroup() %>% 
  filter(diff_ath != 0) %>% 
  mutate(diff_ts = as.numeric(timestamp - lag(timestamp))) -> all_dat_ath
```

```{r warning = FALSE, message = FALSE}
## plot all time highs
all_dat %>% 
  ggplot(aes(x = timestamp, y = close)) +
  geom_line() +
  geom_point(data = all_dat_ath, aes(x = timestamp, y = close), color = "green") +
  xlab("Date") +
  ylab("Close") +
  theme_classic() +
  ggtitle("SPY All Time Highs") -> plot_ath

plot_ath
```

The second half of the dataset has significantly more ATHs than the first. Would have prefered a more balanced universe over time, but oh well. 

We'll calculate all time highs (ATH) and the time difference between consecutive ones. Let's assume that a "dip" must consist of at least three days: all time high, min, next all time high. Therefore, we'll filter out back-to-back days of ATHs.

```{r}
## calc all time highs (ath) + difference between ath
all_dat %>% 
  mutate(row_id = row_number()
         , ath = cummax(high)) %>% 
  group_by() %>% 
  mutate(diff_ath = ath - lag(ath)) %>% 
  ungroup() %>% 
  filter(diff_ath != 0) %>% 
  mutate(diff_ts = as.numeric(timestamp - lag(timestamp))) -> all_dat_ath
```

Now, I am sure there is an easier way to calculate drawdowns between two known points (like using the PerformanceAnalytics package), I like to make things challenging for myself, so we'll calculate drawdowns as follows:

1. Get dates of consecutive ATH pairs.
2. Filter original price dataset to contain all dates between those from Step 1.
3. Calculate minimum price between ATH pairs.
4. Subtract minimum from first ATH.

```{r}
## loop through consecutive pairs of ath_ind
drawdown_dat <- data.frame(row_id = as.numeric()
                           , drawdown = as.numeric()
                           , drawndown_dt = as.character())

for(i in 1:(nrow(all_dat_ath)-1)){
  
  # get timestamps of consecutive ath
  ath1_ts <- all_dat_ath[i, ]$timestamp
  ath2_ts <- all_dat_ath[i + 1, ]$timestamp
  
  # calc min between timestamps
  all_dat %>% 
    filter(timestamp >= ath1_ts, timestamp <= ath2_ts) -> intra_peak_price
  
  # only aths with more than 1-day in between
  if(nrow(intra_peak_price) > 2){
    
    ath1_line <- head(intra_peak_price, 1)
    ath2_line <- tail(intra_peak_price, 1)
    dd_line <- intra_peak_price[intra_peak_price$low == min(intra_peak_price$low), ]
    
    intra_peak_price %>% 
      group_by() %>% 
      summarise(prior_peak = ath1_line$high
                , valley = min(low)
                , drawdown = ((valley - prior_peak)) / prior_peak) %>% 
      ungroup() -> drawdown_tmp 
    
    drawdown_tmp %>% 
      inner_join(dd_line, by = c("valley" = "low")) %>% 
      rename("drawdown_dt" = "timestamp") %>% 
      select(row_id, drawdown_dt, drawdown) -> drawdown_dat_add
    
    drawdown_dat_add %>% 
      rbind.data.frame(drawdown_dat) -> drawdown_dat
    
    ## Doesn't non-consistent arrow direction drive you crazy?
  }
}
```

With all our drawdowns calculated, let's break those down into "fear buckets" -- how much sell off should you wait for before buying in?:
* -1% to -5%
* -5% to -10%
* -10% to -20%
* < -20%

Each category plotted below, with the max drawdown of -57% occuring during the financial crisis in 2008.

```{r echo = FALSE}
drawdown_dat %>% 
  mutate(drawdown = as.numeric(unlist(drawdown))) %>% 
  mutate(dd_thresh = case_when (drawdown <= -0.01 & drawdown > -0.05 ~ "-1% to -5%"
                                , drawdown <= -0.05 & drawdown > -0.10 ~ "-5% to -10%"
                                , drawdown <= -0.1 & drawdown > -0.20 ~ "-10% to -20%"
                                , drawdown <= -0.2 ~ "< -20%")) %>% 
  filter(!is.na(dd_thresh)) -> drawdown_cat

all_dat %>%
  ggplot(aes(x = timestamp, y = close)) +
  geom_line() +
  geom_vline(data = drawdown_cat %>% filter(dd_thresh == "-1% to -5%")
             , aes(xintercept = drawdown_dt), color = "green") +
  xlab("Date") +
  ylab("Close") +
  theme_classic() +
  ggtitle("-1% to -5%") -> plot_thresh1

all_dat %>% 
  ggplot(aes(x = timestamp, y = close)) +
  geom_line() +
  geom_vline(data = drawdown_cat %>% filter(dd_thresh == "-5% to -10%")
             , aes(xintercept = drawdown_dt), color = "blue") +
  xlab("Date") +
  ylab("Close") +
  theme_classic() +
  ggtitle("-5% to -10%") -> plot_thresh2

all_dat %>% 
  ggplot(aes(x = timestamp, y = close)) +
  geom_line() +
  geom_vline(data = drawdown_cat %>% filter(dd_thresh == "-10% to -20%")
             , aes(xintercept = drawdown_dt), color = "orange") +
  xlab("Date") +
  ylab("Close") +
  theme_classic() +
  ggtitle("-10% to -20%") -> plot_thresh3

all_dat %>% 
  ggplot(aes(x = timestamp, y = close)) +
  geom_line() +
  geom_vline(data = drawdown_cat %>% filter(dd_thresh == "< -20%")
             , aes(xintercept = drawdown_dt), color = "red") +
  xlab("Date") +
  ylab("Close") +
  theme_classic() +
  ggtitle("< -20%") -> plot_thresh4

```

```{r echo = FALSE, fig.width = 8.5, fig.height = 6}
grid.arrange(plot_thresh1, plot_thresh2, plot_thresh3, plot_thresh4)
```

Surprisingly (?), returns in each drawdown category (dd_cat) are positive over the next 20, 50, 100, and 200 trading days from the sell off minimum.

```{rm echo = FALSE}
dip_performance %>% 
  group_by(dd_cat) %>% 
  summarise(n = n()
            , d20 = mean(d20, na.rm = TRUE)
            , d50 = mean(d50, na.rm = TRUE)
            , d100 = mean(d100, na.rm = TRUE)
            , d200 = mean(d200, na.rm = TRUE)) %>% 
  ungroup() -> dip_performance_sum

dip_performance_sum
```

Obviously we can't know a drawdown actually falls into one of those categories until the next ATH is in place, but we still see that "buying the dip" produce optimistic results. While it would be hard to get in at a "3 % correct" only for prices to sell off to -%50, as long as you keep buying in, things may turn around in the long term. 
